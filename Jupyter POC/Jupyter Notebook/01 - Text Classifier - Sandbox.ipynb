{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(r\"../Data/Sample Data 1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Places &amp; Travel</td>\n",
       "      <td>[the, budget-minded, traveler, podcast, is, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Food</td>\n",
       "      <td>[the, official, podcast, of, bourbon, ., featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>[..., our, most, human, experiences, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>[a, show, about, politics, with, no, agenda, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Careers</td>\n",
       "      <td>[made, for, profit, is, a, podcast, where, we,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Genre                                        Description\n",
       "0  Places & Travel  [the, budget-minded, traveler, podcast, is, yo...\n",
       "1             Food  [the, official, podcast, of, bourbon, ., featu...\n",
       "2  Social Sciences          [..., our, most, human, experiences, ...]\n",
       "3  News & Politics  [a, show, about, politics, with, no, agenda, ,...\n",
       "4          Careers  [made, for, profit, is, a, podcast, where, we,..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove blank rows\n",
    "corpus['Description'].dropna(inplace=True)\n",
    "# Change all text to lower case\n",
    "corpus['Description'] = [entry.lower() for entry in corpus['Description']]\n",
    "# Tokenization\n",
    "corpus['Description']= [word_tokenize(entry) for entry in corpus['Description']]\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words, non-numeric and perfom Word Stemming/Lemmenting.\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(corpus['Description']):\n",
    "    Final_words = []\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    for word, tag in pos_tag(entry):\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    corpus.loc[index,'description_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Description</th>\n",
       "      <th>description_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Places &amp; Travel</td>\n",
       "      <td>[the, budget-minded, traveler, podcast, is, yo...</td>\n",
       "      <td>['traveler', 'podcast', 'source', 'everyday', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Food</td>\n",
       "      <td>[the, official, podcast, of, bourbon, ., featu...</td>\n",
       "      <td>['official', 'podcast', 'bourbon', 'feature', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>[..., our, most, human, experiences, ...]</td>\n",
       "      <td>['human', 'experience']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>[a, show, about, politics, with, no, agenda, ,...</td>\n",
       "      <td>['show', 'politics', 'agenda', 'adam', 'curry'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Careers</td>\n",
       "      <td>[made, for, profit, is, a, podcast, where, we,...</td>\n",
       "      <td>['make', 'profit', 'podcast', 'talk', 'busines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Genre                                        Description  \\\n",
       "0  Places & Travel  [the, budget-minded, traveler, podcast, is, yo...   \n",
       "1             Food  [the, official, podcast, of, bourbon, ., featu...   \n",
       "2  Social Sciences          [..., our, most, human, experiences, ...]   \n",
       "3  News & Politics  [a, show, about, politics, with, no, agenda, ,...   \n",
       "4          Careers  [made, for, profit, is, a, podcast, where, we,...   \n",
       "\n",
       "                                   description_final  \n",
       "0  ['traveler', 'podcast', 'source', 'everyday', ...  \n",
       "1  ['official', 'podcast', 'bourbon', 'feature', ...  \n",
       "2                            ['human', 'experience']  \n",
       "3  ['show', 'politics', 'agenda', 'adam', 'curry'...  \n",
       "4  ['make', 'profit', 'podcast', 'talk', 'busines...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(corpus['description_final'],corpus['Genre'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD\n",
    "#Encoder = LabelEncoder()\n",
    "#Train_Y = Encoder.fit_transform(Train_Y)\n",
    "#Test_Y = Encoder.fit_transform(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD\n",
    "#Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "#Tfidf_vect.fit(corpus['description_final'])\n",
    "#Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "#Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD\n",
    "# fit the training dataset on the NB classifier\n",
    "#Naive = naive_bayes.MultinomialNB()\n",
    "#Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "#predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "#print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "NBmodel = make_pipeline(TfidfVectorizer(), naive_bayes.MultinomialNB())\n",
    "SVMmodel = make_pipeline(TfidfVectorizer(), svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto'))\n",
    "# Train the model using the training data\n",
    "NBmodel.fit(Train_X, Train_Y)\n",
    "SVMmodel.fit(Train_X, Train_Y)\n",
    "# Predict the categories of the test data\n",
    "NB_predicted_categories = NBmodel.predict(Test_X)\n",
    "SVM_predicted_categories = SVMmodel.predict(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  45.42566709021601\n",
      "SVM Accuracy Score ->  51.207115628970776\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(NB_predicted_categories, Test_Y)*100)\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(SVM_predicted_categories, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = pd.read_csv(r\"../Data/Sample Data 2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arts</td>\n",
       "      <td>[bestselling, author, elizabeth, gilbert, retu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Video Games</td>\n",
       "      <td>[the, leaders, in, gaming, news, hand-pick, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business News</td>\n",
       "      <td>[the, tech, m, &amp;, a, podcast, pulls, from, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Management &amp; Marketing</td>\n",
       "      <td>[a, podcast, about, entrepreneurs, who, quit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medicine</td>\n",
       "      <td>[a, podcast, about, how, doctors, think, ., pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Genre                                        Description\n",
       "0                    Arts  [bestselling, author, elizabeth, gilbert, retu...\n",
       "1             Video Games  [the, leaders, in, gaming, news, hand-pick, th...\n",
       "2           Business News  [the, tech, m, &, a, podcast, pulls, from, the...\n",
       "3  Management & Marketing  [a, podcast, about, entrepreneurs, who, quit, ...\n",
       "4                Medicine  [a, podcast, about, how, doctors, think, ., pr..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove blank rows\n",
    "corpus2['Description'].dropna(inplace=True)\n",
    "# Change all text to lower case\n",
    "corpus2['Description'] = [entry.lower() for entry in corpus2['Description']]\n",
    "# Tokenization\n",
    "corpus2['Description']= [word_tokenize(entry) for entry in corpus2['Description']]\n",
    "corpus2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words, non-numeric and perfom Word Stemming/Lemmenting.\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(corpus2['Description']):\n",
    "    Final_words = []\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    for word, tag in pos_tag(entry):\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    corpus2.loc[index,'description_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Careers' 'Video Games' 'Gadgets' ... 'Careers' 'Video Games' 'Sexuality']\n",
      "Naive Bayes Accuracy Score ->  44.7361840460115\n"
     ]
    }
   ],
   "source": [
    "predicted_categories = model.predict(corpus2['description_final'])\n",
    "\n",
    "print(predicted_categories)\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predicted_categories, corpus2['Genre'])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
